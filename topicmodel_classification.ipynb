{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-Label Classification Using Neural Network"
      ],
      "metadata": {
        "id": "xl0sYBVUc6TB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBkePgLSHarp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import ast\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset class definition\n",
        "\n",
        "class TensorData(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = torch.tensor(x, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "        self.length = self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "metadata": {
        "id": "guE-RkicNFG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Neural network for multilabel classification\n",
        "\n",
        "class MultiLabelClassifyNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MultiLabelClassifyNN, self).__init__()\n",
        "        self.input = nn.Linear(3072, 1024)\n",
        "        self.h1 = nn.Linear(1024, 512)\n",
        "        self.output = nn.Linear(512, 50)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.input(x))\n",
        "        x = F.relu(self.h1(x))\n",
        "        x = torch.sigmoid(self.output(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "XvTMSzi9HoVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_MultiLabelClassifyNN(epochs, train_dataloader, dev_dataloader):\n",
        "    best_loss = float('inf')\n",
        "    best_model = None\n",
        "    patience = 7\n",
        "    no_improvement = 0\n",
        "\n",
        "    model = MultiLabelClassifyNN()\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for x_batch, y_batch in train_dataloader:\n",
        "            y_pred = model(x_batch)\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        dev_loss, accuracy_dev = evaluate_model(model, dev_dataloader, criterion)\n",
        "\n",
        "        if dev_loss < best_loss:\n",
        "            best_loss = dev_loss\n",
        "            best_model = model\n",
        "            no_improvement = 0\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "            if no_improvement >= patience:\n",
        "                print(f\"Early stopping at epoch {epoch + 1} due to no improvement in validation loss.\\n\")\n",
        "                break\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}] | Train Loss: {train_loss/len(train_dataloader):.4f} | Dev Loss: {dev_loss:.4f} | Dev Accuracy: {accuracy_dev:.2f}%\")\n",
        "\n",
        "    return best_model"
      ],
      "metadata": {
        "id": "_498GkWzL5E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in dataloader:\n",
        "            outputs = model(x_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            predictions = (outputs >= 0.5).float()\n",
        "            correct += (predictions == y_batch).float().sum().item()\n",
        "            total += y_batch.numel()\n",
        "\n",
        "    accuracy = (100 * correct) / total\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "\n",
        "    return average_loss, accuracy"
      ],
      "metadata": {
        "id": "4clJGzonI-a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV data for processing using dataloader\n",
        "\n",
        "def load_data_from_csv(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    embeddings = df['openai_embedding'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    target_columns = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13',\n",
        "                      '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
        "                      '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n",
        "                      '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n",
        "    targets = df[target_columns].values\n",
        "    print(targets)\n",
        "\n",
        "    return embeddings, targets\n"
      ],
      "metadata": {
        "id": "YqsXyFa_OJ2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions on a dataset\n",
        "def predict(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for x_batch, _ in dataloader:\n",
        "            outputs = model(x_batch)\n",
        "            predictions.append(outputs)\n",
        "    return torch.cat(predictions, dim=0)\n",
        "\n",
        "# Function to map binary predictions to topic indices\n",
        "def get_predicted_topics(predictions):\n",
        "    topic_indices = []\n",
        "    for prediction in predictions:\n",
        "        topics = [i for i, val in enumerate(prediction) if val == 1.0]\n",
        "        topic_indices.append(topics)\n",
        "    return topic_indices\n"
      ],
      "metadata": {
        "id": "p8HrnXOHHrB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting data\n",
        "train_file_path = '/content/frc_train_data.csv'\n",
        "val_file_path = '/content/frc_val_data.csv'\n",
        "\n",
        "train_embeddings, train_targets = load_data_from_csv(train_file_path)\n",
        "val_embeddings, val_targets = load_data_from_csv(val_file_path)\n",
        "\n",
        "# Convert data using dataloader\n",
        "train_dataset = TensorData(train_embeddings, train_targets)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "val_dataset = TensorData(val_embeddings, val_targets)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "QM4UDY_rK12i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f24147-18a4-407e-c610-eed974056590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "[[0 0 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[23]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHtzYa-NS9OS",
        "outputId": "367a0075-e2c4-41e9-f32f-51703160cb8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 0.0500, -0.0448, -0.0137,  ...,  0.0047,  0.0063,  0.0201]),\n",
              " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "         1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tKTbV-LpSz1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and find best model\n",
        "\n",
        "best_model = train_MultiLabelClassifyNN(100, train_dataloader, val_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv__HqBUK2Nw",
        "outputId": "8a249411-491f-49e9-e359-6d20c7862c2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] | Train Loss: 0.6917 | Dev Loss: 0.6887 | Dev Accuracy: 56.99%\n",
            "Epoch [2/100] | Train Loss: 0.6857 | Dev Loss: 0.6828 | Dev Accuracy: 76.91%\n",
            "Epoch [3/100] | Train Loss: 0.6798 | Dev Loss: 0.6768 | Dev Accuracy: 90.03%\n",
            "Epoch [4/100] | Train Loss: 0.6738 | Dev Loss: 0.6709 | Dev Accuracy: 93.98%\n",
            "Epoch [5/100] | Train Loss: 0.6679 | Dev Loss: 0.6649 | Dev Accuracy: 94.00%\n",
            "Epoch [6/100] | Train Loss: 0.6619 | Dev Loss: 0.6589 | Dev Accuracy: 94.00%\n",
            "Epoch [7/100] | Train Loss: 0.6558 | Dev Loss: 0.6527 | Dev Accuracy: 94.00%\n",
            "Epoch [8/100] | Train Loss: 0.6495 | Dev Loss: 0.6463 | Dev Accuracy: 94.00%\n",
            "Epoch [9/100] | Train Loss: 0.6430 | Dev Loss: 0.6396 | Dev Accuracy: 94.00%\n",
            "Epoch [10/100] | Train Loss: 0.6362 | Dev Loss: 0.6327 | Dev Accuracy: 94.00%\n",
            "Epoch [11/100] | Train Loss: 0.6291 | Dev Loss: 0.6254 | Dev Accuracy: 94.00%\n",
            "Epoch [12/100] | Train Loss: 0.6215 | Dev Loss: 0.6176 | Dev Accuracy: 94.00%\n",
            "Epoch [13/100] | Train Loss: 0.6135 | Dev Loss: 0.6092 | Dev Accuracy: 94.00%\n",
            "Epoch [14/100] | Train Loss: 0.6049 | Dev Loss: 0.6002 | Dev Accuracy: 94.00%\n",
            "Epoch [15/100] | Train Loss: 0.5955 | Dev Loss: 0.5905 | Dev Accuracy: 94.00%\n",
            "Epoch [16/100] | Train Loss: 0.5853 | Dev Loss: 0.5797 | Dev Accuracy: 94.00%\n",
            "Epoch [17/100] | Train Loss: 0.5740 | Dev Loss: 0.5679 | Dev Accuracy: 94.00%\n",
            "Epoch [18/100] | Train Loss: 0.5616 | Dev Loss: 0.5548 | Dev Accuracy: 94.00%\n",
            "Epoch [19/100] | Train Loss: 0.5477 | Dev Loss: 0.5401 | Dev Accuracy: 94.00%\n",
            "Epoch [20/100] | Train Loss: 0.5322 | Dev Loss: 0.5237 | Dev Accuracy: 94.00%\n",
            "Epoch [21/100] | Train Loss: 0.5148 | Dev Loss: 0.5052 | Dev Accuracy: 94.00%\n",
            "Epoch [22/100] | Train Loss: 0.4953 | Dev Loss: 0.4845 | Dev Accuracy: 94.00%\n",
            "Epoch [23/100] | Train Loss: 0.4735 | Dev Loss: 0.4615 | Dev Accuracy: 94.00%\n",
            "Epoch [24/100] | Train Loss: 0.4494 | Dev Loss: 0.4363 | Dev Accuracy: 94.00%\n",
            "Epoch [25/100] | Train Loss: 0.4233 | Dev Loss: 0.4093 | Dev Accuracy: 94.00%\n",
            "Epoch [26/100] | Train Loss: 0.3957 | Dev Loss: 0.3811 | Dev Accuracy: 94.00%\n",
            "Epoch [27/100] | Train Loss: 0.3675 | Dev Loss: 0.3530 | Dev Accuracy: 94.00%\n",
            "Epoch [28/100] | Train Loss: 0.3399 | Dev Loss: 0.3262 | Dev Accuracy: 94.00%\n",
            "Epoch [29/100] | Train Loss: 0.3143 | Dev Loss: 0.3019 | Dev Accuracy: 94.00%\n",
            "Epoch [30/100] | Train Loss: 0.2917 | Dev Loss: 0.2809 | Dev Accuracy: 94.00%\n",
            "Epoch [31/100] | Train Loss: 0.2726 | Dev Loss: 0.2637 | Dev Accuracy: 94.00%\n",
            "Epoch [32/100] | Train Loss: 0.2572 | Dev Loss: 0.2500 | Dev Accuracy: 94.00%\n",
            "Epoch [33/100] | Train Loss: 0.2451 | Dev Loss: 0.2394 | Dev Accuracy: 94.00%\n",
            "Epoch [34/100] | Train Loss: 0.2359 | Dev Loss: 0.2314 | Dev Accuracy: 94.00%\n",
            "Epoch [35/100] | Train Loss: 0.2289 | Dev Loss: 0.2254 | Dev Accuracy: 94.00%\n",
            "Epoch [36/100] | Train Loss: 0.2237 | Dev Loss: 0.2208 | Dev Accuracy: 94.00%\n",
            "Epoch [37/100] | Train Loss: 0.2198 | Dev Loss: 0.2174 | Dev Accuracy: 94.00%\n",
            "Epoch [38/100] | Train Loss: 0.2168 | Dev Loss: 0.2148 | Dev Accuracy: 94.00%\n",
            "Epoch [39/100] | Train Loss: 0.2145 | Dev Loss: 0.2128 | Dev Accuracy: 94.00%\n",
            "Epoch [40/100] | Train Loss: 0.2128 | Dev Loss: 0.2112 | Dev Accuracy: 94.00%\n",
            "Epoch [41/100] | Train Loss: 0.2114 | Dev Loss: 0.2100 | Dev Accuracy: 94.00%\n",
            "Epoch [42/100] | Train Loss: 0.2103 | Dev Loss: 0.2090 | Dev Accuracy: 94.00%\n",
            "Epoch [43/100] | Train Loss: 0.2094 | Dev Loss: 0.2082 | Dev Accuracy: 94.00%\n",
            "Epoch [44/100] | Train Loss: 0.2088 | Dev Loss: 0.2075 | Dev Accuracy: 94.00%\n",
            "Epoch [45/100] | Train Loss: 0.2081 | Dev Loss: 0.2069 | Dev Accuracy: 94.00%\n",
            "Epoch [46/100] | Train Loss: 0.2076 | Dev Loss: 0.2064 | Dev Accuracy: 94.00%\n",
            "Epoch [47/100] | Train Loss: 0.2072 | Dev Loss: 0.2060 | Dev Accuracy: 94.00%\n",
            "Epoch [48/100] | Train Loss: 0.2068 | Dev Loss: 0.2056 | Dev Accuracy: 94.00%\n",
            "Epoch [49/100] | Train Loss: 0.2064 | Dev Loss: 0.2053 | Dev Accuracy: 94.00%\n",
            "Epoch [50/100] | Train Loss: 0.2061 | Dev Loss: 0.2050 | Dev Accuracy: 94.00%\n",
            "Epoch [51/100] | Train Loss: 0.2058 | Dev Loss: 0.2047 | Dev Accuracy: 94.00%\n",
            "Epoch [52/100] | Train Loss: 0.2056 | Dev Loss: 0.2045 | Dev Accuracy: 94.00%\n",
            "Epoch [53/100] | Train Loss: 0.2054 | Dev Loss: 0.2043 | Dev Accuracy: 94.00%\n",
            "Epoch [54/100] | Train Loss: 0.2051 | Dev Loss: 0.2041 | Dev Accuracy: 94.00%\n",
            "Epoch [55/100] | Train Loss: 0.2050 | Dev Loss: 0.2039 | Dev Accuracy: 94.00%\n",
            "Epoch [56/100] | Train Loss: 0.2049 | Dev Loss: 0.2037 | Dev Accuracy: 94.00%\n",
            "Epoch [57/100] | Train Loss: 0.2047 | Dev Loss: 0.2036 | Dev Accuracy: 94.00%\n",
            "Epoch [58/100] | Train Loss: 0.2045 | Dev Loss: 0.2034 | Dev Accuracy: 94.00%\n",
            "Epoch [59/100] | Train Loss: 0.2044 | Dev Loss: 0.2033 | Dev Accuracy: 94.00%\n",
            "Epoch [60/100] | Train Loss: 0.2043 | Dev Loss: 0.2032 | Dev Accuracy: 94.00%\n",
            "Epoch [61/100] | Train Loss: 0.2042 | Dev Loss: 0.2031 | Dev Accuracy: 94.00%\n",
            "Epoch [62/100] | Train Loss: 0.2041 | Dev Loss: 0.2030 | Dev Accuracy: 94.00%\n",
            "Epoch [63/100] | Train Loss: 0.2041 | Dev Loss: 0.2029 | Dev Accuracy: 94.00%\n",
            "Epoch [64/100] | Train Loss: 0.2039 | Dev Loss: 0.2028 | Dev Accuracy: 94.00%\n",
            "Epoch [65/100] | Train Loss: 0.2038 | Dev Loss: 0.2027 | Dev Accuracy: 94.00%\n",
            "Epoch [66/100] | Train Loss: 0.2037 | Dev Loss: 0.2027 | Dev Accuracy: 94.00%\n",
            "Epoch [67/100] | Train Loss: 0.2037 | Dev Loss: 0.2026 | Dev Accuracy: 94.00%\n",
            "Epoch [68/100] | Train Loss: 0.2036 | Dev Loss: 0.2025 | Dev Accuracy: 94.00%\n",
            "Epoch [69/100] | Train Loss: 0.2035 | Dev Loss: 0.2025 | Dev Accuracy: 94.00%\n",
            "Epoch [70/100] | Train Loss: 0.2035 | Dev Loss: 0.2024 | Dev Accuracy: 94.00%\n",
            "Epoch [71/100] | Train Loss: 0.2035 | Dev Loss: 0.2023 | Dev Accuracy: 94.00%\n",
            "Epoch [72/100] | Train Loss: 0.2033 | Dev Loss: 0.2023 | Dev Accuracy: 94.00%\n",
            "Epoch [73/100] | Train Loss: 0.2033 | Dev Loss: 0.2022 | Dev Accuracy: 94.00%\n",
            "Epoch [74/100] | Train Loss: 0.2033 | Dev Loss: 0.2022 | Dev Accuracy: 94.00%\n",
            "Epoch [75/100] | Train Loss: 0.2033 | Dev Loss: 0.2022 | Dev Accuracy: 94.00%\n",
            "Epoch [76/100] | Train Loss: 0.2032 | Dev Loss: 0.2021 | Dev Accuracy: 94.00%\n",
            "Epoch [77/100] | Train Loss: 0.2032 | Dev Loss: 0.2021 | Dev Accuracy: 94.00%\n",
            "Epoch [78/100] | Train Loss: 0.2030 | Dev Loss: 0.2020 | Dev Accuracy: 94.00%\n",
            "Epoch [79/100] | Train Loss: 0.2030 | Dev Loss: 0.2020 | Dev Accuracy: 94.00%\n",
            "Epoch [80/100] | Train Loss: 0.2030 | Dev Loss: 0.2020 | Dev Accuracy: 94.00%\n",
            "Epoch [81/100] | Train Loss: 0.2029 | Dev Loss: 0.2019 | Dev Accuracy: 94.00%\n",
            "Epoch [82/100] | Train Loss: 0.2029 | Dev Loss: 0.2019 | Dev Accuracy: 94.00%\n",
            "Epoch [83/100] | Train Loss: 0.2029 | Dev Loss: 0.2019 | Dev Accuracy: 94.00%\n",
            "Epoch [84/100] | Train Loss: 0.2028 | Dev Loss: 0.2018 | Dev Accuracy: 94.00%\n",
            "Epoch [85/100] | Train Loss: 0.2028 | Dev Loss: 0.2018 | Dev Accuracy: 94.00%\n",
            "Epoch [86/100] | Train Loss: 0.2028 | Dev Loss: 0.2018 | Dev Accuracy: 94.00%\n",
            "Epoch [87/100] | Train Loss: 0.2028 | Dev Loss: 0.2018 | Dev Accuracy: 94.00%\n",
            "Epoch [88/100] | Train Loss: 0.2027 | Dev Loss: 0.2017 | Dev Accuracy: 94.00%\n",
            "Epoch [89/100] | Train Loss: 0.2027 | Dev Loss: 0.2017 | Dev Accuracy: 94.00%\n",
            "Epoch [90/100] | Train Loss: 0.2027 | Dev Loss: 0.2017 | Dev Accuracy: 94.00%\n",
            "Epoch [91/100] | Train Loss: 0.2027 | Dev Loss: 0.2017 | Dev Accuracy: 94.00%\n",
            "Epoch [92/100] | Train Loss: 0.2027 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [93/100] | Train Loss: 0.2026 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [94/100] | Train Loss: 0.2026 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [95/100] | Train Loss: 0.2026 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [96/100] | Train Loss: 0.2026 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [97/100] | Train Loss: 0.2026 | Dev Loss: 0.2016 | Dev Accuracy: 94.00%\n",
            "Epoch [98/100] | Train Loss: 0.2025 | Dev Loss: 0.2015 | Dev Accuracy: 94.00%\n",
            "Epoch [99/100] | Train Loss: 0.2025 | Dev Loss: 0.2015 | Dev Accuracy: 94.00%\n",
            "Epoch [100/100] | Train Loss: 0.2025 | Dev Loss: 0.2015 | Dev Accuracy: 94.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load validation data\n",
        "test_file_path = '/content/frc_test_data.csv'\n",
        "test_embeddings, test_targets = load_data_from_csv(test_file_path)\n",
        "\n",
        "test_dataset = TensorData(test_embeddings, test_targets)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "3IiyOQI-S3CD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e10b0b-469d-4e85-a94b-0bfd4350af73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 1]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions and convert to binary\n",
        "predictions = predict(best_model, test_dataloader)\n",
        "print(predictions)\n",
        "\n",
        "predicted_topics = (predictions >= 0.5).float()\n",
        "print(predicted_topics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8W47LbIU5Z",
        "outputId": "762b583a-4332-4194-e210-35a43023d794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0059, 0.0668, 0.1762,  ..., 0.0103, 0.0104, 0.1097],\n",
            "        [0.0073, 0.0736, 0.1851,  ..., 0.0124, 0.0125, 0.1180],\n",
            "        [0.0083, 0.0781, 0.1902,  ..., 0.0139, 0.0140, 0.1231],\n",
            "        ...,\n",
            "        [0.0071, 0.0729, 0.1836,  ..., 0.0121, 0.0122, 0.1167],\n",
            "        [0.0063, 0.0690, 0.1794,  ..., 0.0110, 0.0110, 0.1126],\n",
            "        [0.0079, 0.0769, 0.1889,  ..., 0.0134, 0.0135, 0.1215]])\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[123]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3kJUMCWJKOq",
        "outputId": "4479d869-b17b-4410-9d3a-0fba1affdc21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0062, 0.0683, 0.1784, 0.1527, 0.1217, 0.1208, 0.0505, 0.0088, 0.1208,\n",
              "        0.0558, 0.0115, 0.0395, 0.0604, 0.0182, 0.0065, 0.0643, 0.0205, 0.0062,\n",
              "        0.0372, 0.0201, 0.0164, 0.0065, 0.0101, 0.2057, 0.0067, 0.0081, 0.1698,\n",
              "        0.0170, 0.0189, 0.0578, 0.0902, 0.0308, 0.0091, 0.0377, 0.0727, 0.0938,\n",
              "        0.0337, 0.0692, 0.1022, 0.1006, 0.0535, 0.0403, 0.0919, 0.0674, 0.0493,\n",
              "        0.0265, 0.0623, 0.0108, 0.0108, 0.1114])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.topk(predictions[123], 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd5YhmZvRJ8m",
        "outputId": "6c4d5c24-1818-4dc7-ab91-d7696de5fa2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([0.2057, 0.1784, 0.1698]),\n",
              "indices=tensor([23,  2, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_topics[123]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CooqdxMsLBU_",
        "outputId": "d6a65cb3-828c-4b84-b0c0-6d106796918f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_targets[123]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLrHOn4tLRE-",
        "outputId": "1adad043-150a-4209-a5fb-88ec6408f255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.topk(torch.from_numpy(test_targets[123]), 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBX7Z24aRfkM",
        "outputId": "1d3208a2-32e9-4602-db28-f9bef0e057d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.topk(\n",
              "values=tensor([1, 1, 1]),\n",
              "indices=tensor([26, 30, 34]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted topics\n",
        "predicted_topics_indices = get_predicted_topics(predicted_topics)\n",
        "\n",
        "for i, topics in enumerate(predicted_topics_indices[:10]):\n",
        "    print(f\"Sample {i + 1} Predicted Topics: {topics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzMPqmDxIru9",
        "outputId": "f79f6806-1641-4bb0-e2f2-e297cf49a7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 Predicted Topics: []\n",
            "Sample 2 Predicted Topics: []\n",
            "Sample 3 Predicted Topics: []\n",
            "Sample 4 Predicted Topics: []\n",
            "Sample 5 Predicted Topics: []\n",
            "Sample 6 Predicted Topics: []\n",
            "Sample 7 Predicted Topics: []\n",
            "Sample 8 Predicted Topics: []\n",
            "Sample 9 Predicted Topics: []\n",
            "Sample 10 Predicted Topics: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing predicted and true topics\n",
        "for i in range(20):\n",
        "    print(f\"Sample {i + 1} True Topics: {test_targets[i]}, Predicted Topics: {predicted_topics_indices[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_YmnbvdI6PG",
        "outputId": "dfa3cedd-05dc-41cf-b021-cc90b4e4e5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 True Topics: [0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 2 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 3 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1], Predicted Topics: []\n",
            "Sample 4 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 1], Predicted Topics: []\n",
            "Sample 5 True Topics: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 6 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 7 True Topics: [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 8 True Topics: [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 9 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 10 True Topics: [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 1 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 11 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 12 True Topics: [0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 13 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1], Predicted Topics: []\n",
            "Sample 14 True Topics: [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 15 True Topics: [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 16 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 17 True Topics: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 0 1], Predicted Topics: []\n",
            "Sample 18 True Topics: [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0], Predicted Topics: []\n",
            "Sample 19 True Topics: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 1], Predicted Topics: []\n",
            "Sample 20 True Topics: [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0], Predicted Topics: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "  print(torch.topk(predictions[i],3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spm8-qd_UKj1",
        "outputId": "c6d38a44-6783-4080-9bc8-b75c97968c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.topk(\n",
            "values=tensor([0.2035, 0.1762, 0.1680]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2127, 0.1851, 0.1766]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2176, 0.1902, 0.1823]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2087, 0.1815, 0.1731]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2078, 0.1802, 0.1724]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2071, 0.1797, 0.1712]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2106, 0.1825, 0.1746]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2099, 0.1828, 0.1743]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2034, 0.1760, 0.1675]),\n",
            "indices=tensor([23,  2, 26]))\n",
            "torch.return_types.topk(\n",
            "values=tensor([0.2117, 0.1840, 0.1761]),\n",
            "indices=tensor([23,  2, 26]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map top 3 predictions to topic indices\n",
        "def get_top_3_predicted_topics(predictions):\n",
        "    topic_indices = []\n",
        "    for prediction in predictions:\n",
        "        topics = torch.topk(prediction, 3).indices\n",
        "        topic_indices.append(topics)\n",
        "    return topic_indices\n"
      ],
      "metadata": {
        "id": "gquXnWyCJiOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_top_3_topics = get_top_3_predicted_topics(predictions)"
      ],
      "metadata": {
        "id": "JlMjmLjCTmak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing predicted and true topics\n",
        "for i in range(20):\n",
        "    print(f\"Sample {i + 1} True Topics: \\\n",
        "    {torch.topk(torch.from_numpy(test_targets[i]), 3).indices}, \\\n",
        "    Predicted Topics: {predicted_top_3_topics[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xDCGtzjTTWz",
        "outputId": "9c9fb3bb-16d3-458b-c133-66e689f2c314"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 True Topics:     tensor([23,  8,  5]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 2 True Topics:     tensor([39, 16, 29]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 3 True Topics:     tensor([49, 18, 39]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 4 True Topics:     tensor([49, 29, 40]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 5 True Topics:     tensor([35,  8,  2]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 6 True Topics:     tensor([23, 30, 12]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 7 True Topics:     tensor([23,  5, 37]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 8 True Topics:     tensor([35,  8,  2]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 9 True Topics:     tensor([26, 34, 15]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 10 True Topics:     tensor([ 8, 39, 38]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 11 True Topics:     tensor([26, 42, 15]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 12 True Topics:     tensor([26,  3,  2]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 13 True Topics:     tensor([35, 29, 49]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 14 True Topics:     tensor([ 2, 34, 26]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 15 True Topics:     tensor([23,  8,  6]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 16 True Topics:     tensor([42, 23, 19]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 17 True Topics:     tensor([49, 18, 39]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 18 True Topics:     tensor([ 6,  4, 35]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 19 True Topics:     tensor([49, 44,  4]),     Predicted Topics: tensor([23,  2, 26])\n",
            "Sample 20 True Topics:     tensor([ 9, 30, 43]),     Predicted Topics: tensor([23,  2, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression for Multi-Label Classification"
      ],
      "metadata": {
        "id": "L7zi47o8dB-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ],
      "metadata": {
        "id": "vLOzedsJxRnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data_with_two_labels(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    embeddings = df['openai_embedding'].apply(lambda x: ast.literal_eval(x)).tolist()\n",
        "    embeddings = np.array(embeddings)\n",
        "\n",
        "    target_columns = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13',\n",
        "                      '15', '16', '18', '19', '20', '22', '23', '25', '26',\n",
        "                      '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n",
        "                      '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n",
        "    targets = df[target_columns].values\n",
        "\n",
        "    return embeddings, targets"
      ],
      "metadata": {
        "id": "WXoXN0JizbIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file_path = '/content/frc_train_data.csv'\n",
        "test_file_path = '/content/frc_test_data.csv'\n",
        "\n",
        "train_emb, train_targ = load_data_with_two_labels(train_file_path)\n",
        "test_emb, test_targ = load_data_with_two_labels(test_file_path)"
      ],
      "metadata": {
        "id": "bZtH-cvQzyGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# MultiOutputClassifier for multi-label classification\n",
        "multi_target_log_reg = MultiOutputClassifier(log_reg, n_jobs=-1)\n"
      ],
      "metadata": {
        "id": "AS3dvy4QxpNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the mdoel\n",
        "multi_target_log_reg.fit(train_emb, train_targ)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = multi_target_log_reg.predict(test_emb)"
      ],
      "metadata": {
        "id": "uRrJ7FLdx2Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8meGQZtoJPo",
        "outputId": "2746e311-91ee-4f7f-c556-076d1d658325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 1, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(test_targ, y_pred)\n",
        "f1 = f1_score(test_targ, y_pred, average='micro')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SzicRHix4H_",
        "outputId": "97859746-0a83-440f-8d53-fac3ce2f6669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.00\n",
            "F1 Score: 0.44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing topic numbers\n",
        "\n",
        "original_labels = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13',\n",
        "                   '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26',\n",
        "                   '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39',\n",
        "                   '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n",
        "\n",
        "extracted_labels = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13',\n",
        "                    '15', '16', '18', '19', '20', '22', '23', '25', '26', '27', '28', '29', '30',\n",
        "                    '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43',\n",
        "                    '44', '45', '46', '47', '48', '49']\n",
        "\n",
        "ext_to_orig_index = {extracted_labels.index(label): original_labels.index(label) for label in extracted_labels}\n",
        "\n",
        "print(ext_to_orig_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ZyUIU5o47p",
        "outputId": "ecb538b4-4180-4806-ad58-013cee26fd29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 1, 1: 2, 2: 3, 3: 4, 4: 5, 5: 6, 6: 7, 7: 8, 8: 9, 9: 10, 10: 11, 11: 12, 12: 13, 13: 15, 14: 16, 15: 18, 16: 19, 17: 20, 18: 22, 19: 23, 20: 25, 21: 26, 22: 27, 23: 28, 24: 29, 25: 30, 26: 31, 27: 32, 28: 33, 29: 34, 30: 35, 31: 36, 32: 37, 33: 38, 34: 39, 35: 40, 36: 41, 37: 42, 38: 43, 39: 44, 40: 45, 41: 46, 42: 47, 43: 48, 44: 49}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top 3 predicted topics\n",
        "def get_top_3_topics(probs, k=3):\n",
        "    top3_indices = np.argsort(probs, axis=1)[:, -k:]\n",
        "    return top3_indices"
      ],
      "metadata": {
        "id": "EG3qW67L01I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities\n",
        "y_prob = multi_target_log_reg.predict_proba(test_emb)\n",
        "y_prob_matrix = np.hstack([prob[:, 1].reshape(-1, 1) for prob in y_prob])\n",
        "\n",
        "# Get top 3 predicted topics\n",
        "top_3_predicted_topics = get_top_3_topics(y_prob_matrix, k=3)"
      ],
      "metadata": {
        "id": "AMAwtkZ21DbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map predicted indices to original labels\n",
        "def map_to_original_labels(indices, mapping):\n",
        "    return [[mapping[i] for i in row] for row in indices]\n"
      ],
      "metadata": {
        "id": "scCW3sVWpdcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping topics\n",
        "top_3_predicted_topics_mapped = map_to_original_labels(top_3_predicted_topics, ext_to_orig_index)\n"
      ],
      "metadata": {
        "id": "JvqsLqKBp01b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    true_topics = [original_labels.index(extracted_labels[j]) for j in np.where(test_targ[i] == 1)[0].tolist()]\n",
        "    predicted_topics = top_3_predicted_topics_mapped[i]\n",
        "    print(f\"Sample {i + 1} - True Topics: {true_topics}, Predicted Topics: {predicted_topics}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFqlaJ8j1Iq_",
        "outputId": "90648c00-8ee8-499c-bd43-879cd61861e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 1 - True Topics: [5, 8, 23], Predicted Topics: [5, 26, 8]\n",
            "Sample 2 - True Topics: [16, 29, 39], Predicted Topics: [40, 16, 39]\n",
            "Sample 3 - True Topics: [18, 39, 49], Predicted Topics: [49, 38, 18]\n",
            "Sample 4 - True Topics: [29, 40, 49], Predicted Topics: [39, 40, 49]\n",
            "Sample 5 - True Topics: [2, 8, 35], Predicted Topics: [9, 8, 5]\n",
            "Sample 6 - True Topics: [12, 23, 30], Predicted Topics: [30, 12, 23]\n",
            "Sample 7 - True Topics: [5, 23, 37], Predicted Topics: [5, 23, 35]\n",
            "Sample 8 - True Topics: [2, 8, 35], Predicted Topics: [9, 8, 35]\n",
            "Sample 9 - True Topics: [15, 26, 34], Predicted Topics: [49, 26, 3]\n",
            "Sample 10 - True Topics: [8, 38, 39], Predicted Topics: [5, 35, 8]\n",
            "Sample 11 - True Topics: [15, 26, 42], Predicted Topics: [2, 26, 4]\n",
            "Sample 12 - True Topics: [2, 3, 26], Predicted Topics: [26, 46, 3]\n",
            "Sample 13 - True Topics: [29, 35, 49], Predicted Topics: [39, 26, 29]\n",
            "Sample 14 - True Topics: [2, 26, 34], Predicted Topics: [34, 23, 26]\n",
            "Sample 15 - True Topics: [6, 8, 23], Predicted Topics: [37, 4, 6]\n",
            "Sample 16 - True Topics: [19, 23, 42], Predicted Topics: [2, 26, 23]\n",
            "Sample 17 - True Topics: [18, 39, 49], Predicted Topics: [29, 39, 38]\n",
            "Sample 18 - True Topics: [4, 6, 35], Predicted Topics: [8, 4, 6]\n",
            "Sample 19 - True Topics: [4, 44, 49], Predicted Topics: [49, 4, 44]\n",
            "Sample 20 - True Topics: [9, 30, 43], Predicted Topics: [43, 30, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Measuring correctly identified topics\n",
        "\n",
        "def correctly_identified_topics(true_topics, predicted_topics):\n",
        "    total_correct = 0\n",
        "    num_samples = len(true_topics)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        true_set = set(true_topics[i])\n",
        "        pred_set = set(predicted_topics[i])\n",
        "\n",
        "        correct_predictions = len(true_set & pred_set)\n",
        "\n",
        "        total_correct += correct_predictions\n",
        "\n",
        "    avg_correct = total_correct / (num_samples)\n",
        "\n",
        "    return avg_correct, total_correct"
      ],
      "metadata": {
        "id": "8ziGWU39qMsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_true_topics = []\n",
        "\n",
        "for i in range(len(test_targ)):\n",
        "   all_true_topics.append([original_labels.index(extracted_labels[j]) for j in np.where(test_targ[i] == 1)[0].tolist()])"
      ],
      "metadata": {
        "id": "H3FSUe_Lrv7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_correct_topics, total_correct = correctly_identified_topics(all_true_topics, top_3_predicted_topics_mapped)\n",
        "\n",
        "total_avg_correct = (total_correct)/(len(test_targ)*3)\n",
        "print(f\"Average Correctly Identified Topics per Sample: {avg_correct_topics:.2f}\")\n",
        "print(f\"Total Average Correctly Identified Topics: {total_avg_correct:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcwVMGhNsHA6",
        "outputId": "cab3ba61-2520-415f-a19f-8e623defdca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Correctly Identified Topics per Sample: 1.80\n",
            "Total Average Correctly Identified Topics: 0.60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rXatIszgs1WR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}